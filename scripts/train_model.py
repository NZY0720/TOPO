#!/usr/bin/env python3
"""
ä¸»è®­ç»ƒè„šæœ¬ - Power Grid Topology Reconstruction
ç”¨æ³•ï¼špython scripts/train_model.py --config_path config.yaml --data_path ./data
"""

import os
import sys
import argparse
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import torch
import numpy as np
from power_grid_topology.config.base_config import Config, get_default_config
from power_grid_topology.data.data_loader import PowerGridDataLoader
from power_grid_topology.models.graph_transformer import create_model
from power_grid_topology.training.trainer import PowerGridTrainer
from power_grid_topology.evaluation.evaluator import ModelEvaluator
from power_grid_topology.utils.io_utils import load_yaml, save_json, create_experiment_summary
from power_grid_topology.utils.logging_utils import setup_logger


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ç”µåŠ›ç½‘æ ¼æ‹“æ‰‘é‡å»ºæ¨¡å‹è®­ç»ƒ",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--config_path', type=str, default=None,
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆYAMLæ ¼å¼ï¼‰')
    parser.add_argument('--data_path', type=str, required=True,
                       help='æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./outputs',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--experiment_name', type=str, default=None,
                       help='å®éªŒåç§°')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=None,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=None,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='æ‰¹å¤§å°')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model_type', type=str, choices=['standard', 'hybrid'], 
                       default=None, help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--hidden_dim', type=int, default=None,
                       help='éšè—å±‚ç»´åº¦')
    parser.add_argument('--num_heads', type=int, default=None,
                       help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--num_layers', type=int, default=None,
                       help='ç½‘ç»œå±‚æ•°')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--unobservable_ratio', type=float, default=None,
                       help='ä¸å¯è§‚æµ‹èŠ‚ç‚¹æ¯”ä¾‹')
    parser.add_argument('--k_neighbors', type=int, default=None,
                       help='å€™é€‰å›¾kè¿‘é‚»æ•°')
    
    # æ‰§è¡Œé€‰é¡¹
    parser.add_argument('--train_only', action='store_true',
                       help='åªè®­ç»ƒï¼Œä¸è¯„ä¼°')
    parser.add_argument('--resume_from', type=str, default=None,
                       help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    parser.add_argument('--debug', action='store_true',
                       help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    parser.add_argument('--device', type=str, choices=['auto', 'cpu', 'cuda'],
                       default='auto', help='è®¡ç®—è®¾å¤‡')
    
    return parser.parse_args()


def setup_config(args):
    """è®¾ç½®é…ç½®"""
    # åŠ è½½åŸºç¡€é…ç½®
    if args.config_path and os.path.exists(args.config_path):
        print(f"ğŸ“„ åŠ è½½é…ç½®æ–‡ä»¶: {args.config_path}")
        config_dict = load_yaml(args.config_path)
        config = Config.from_dict(config_dict)
    else:
        print("ğŸ“„ ä½¿ç”¨é»˜è®¤é…ç½®")
        config = get_default_config()
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.experiment_name:
        config.experiment.name = args.experiment_name
    
    if args.output_dir:
        config.experiment.output_dir = args.output_dir
        config.experiment.log_dir = os.path.join(args.output_dir, 'logs')
        config.experiment.checkpoint_dir = os.path.join(args.output_dir, 'models')
        config.experiment.figure_dir = os.path.join(args.output_dir, 'figures')
    
    # æ•°æ®é…ç½®
    config.data.data_path = args.data_path
    if args.unobservable_ratio is not None:
        config.data.unobservable_ratio = args.unobservable_ratio
    if args.k_neighbors is not None:
        config.data.candidate_k_neighbors = args.k_neighbors
    
    # è®­ç»ƒé…ç½®
    if args.epochs is not None:
        config.training.epochs = args.epochs
    if args.learning_rate is not None:
        config.training.learning_rate = args.learning_rate
    if args.batch_size is not None:
        config.training.batch_size = args.batch_size
    if args.device != 'auto':
        config.training.device = args.device
    
    # æ¨¡å‹é…ç½®
    if args.model_type is not None:
        config.model.model_type = args.model_type
    if args.hidden_dim is not None:
        config.model.d_hidden = args.hidden_dim
    if args.num_heads is not None:
        config.model.n_heads = args.num_heads
    if args.num_layers is not None:
        config.model.n_layers = args.num_layers
    
    # è°ƒè¯•æ¨¡å¼
    if args.debug:
        config.experiment.debug_mode = True
        config.training.epochs = min(10, config.training.epochs)
        config.data.time_steps = list(range(5))
        config.training.log_every = 1
        config.training.validate_every = 2
    
    return config


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # è®¾ç½®PyTorchçš„ç¡®å®šæ€§è¡Œä¸º
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ç”µåŠ›ç½‘æ ¼æ‹“æ‰‘é‡å»ºè®­ç»ƒ")
    print("=" * 60)
    
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    print(f"ğŸ² éšæœºç§å­è®¾ç½®ä¸º: {args.seed}")
    
    # è®¾ç½®é…ç½®
    config = setup_config(args)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config.experiment.output_dir, exist_ok=True)
    os.makedirs(config.experiment.log_dir, exist_ok=True)
    os.makedirs(config.experiment.checkpoint_dir, exist_ok=True)
    os.makedirs(config.experiment.figure_dir, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(
        'main', 
        os.path.join(config.experiment.log_dir, 'main.log')
    )
    
    logger.info(f"å®éªŒåç§°: {config.experiment.name}")
    logger.info(f"è¾“å‡ºç›®å½•: {config.experiment.output_dir}")
    logger.info(f"æ•°æ®è·¯å¾„: {config.data.data_path}")
    
    try:
        # 1. åŠ è½½æ•°æ®
        print("\nğŸ“‚ æ­¥éª¤ 1/5: åŠ è½½æ•°æ®")
        print("-" * 30)
        
        data_loader = PowerGridDataLoader(config.data)
        data_loader.load_data(config.data.data_path)
        
        # æ¨¡æ‹Ÿéƒ¨åˆ†å¯è§‚æµ‹æ€§
        masked_nodes = data_loader.mask_unobservable_nodes(
            config.data.unobservable_ratio,
            seed=args.seed
        )
        
        # è·å–æ•°æ®ä¿¡æ¯
        data_info = data_loader.get_data_info()
        logger.info(f"æ•°æ®é›†ä¿¡æ¯: {data_info}")
        
        # 2. åˆ›å»ºæ¨¡å‹
        print("\nğŸ§  æ­¥éª¤ 2/5: åˆ›å»ºæ¨¡å‹")
        print("-" * 30)
        
        # è·å–è¾“å…¥ç‰¹å¾ç»´åº¦
        sample_data = data_loader.create_graph_data(0)
        input_dim = sample_data.x.size(1)
        
        model = create_model(config.model, input_dim)
        device = torch.device(config.training.device)
        model = model.to(device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"æ¨¡å‹ç±»å‹: {model.__class__.__name__}")
        print(f"æ€»å‚æ•°æ•°: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"è®¡ç®—è®¾å¤‡: {device}")
        
        logger.info(f"æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå‚æ•°æ•°é‡: {total_params:,}")
        
        # 3. è®­ç»ƒæ¨¡å‹
        print("\nğŸ‹ï¸ æ­¥éª¤ 3/5: è®­ç»ƒæ¨¡å‹")
        print("-" * 30)
        
        trainer = PowerGridTrainer(config)
        
        # ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.resume_from and os.path.exists(args.resume_from):
            print(f"ğŸ“¦ ä»æ£€æŸ¥ç‚¹æ¢å¤: {args.resume_from}")
            trainer.load_checkpoint(args.resume_from)
        
        # å¼€å§‹è®­ç»ƒ
        start_time = time.time()
        trainer.train(data_loader)
        training_time = time.time() - start_time
        
        print(f"âœ… è®­ç»ƒå®Œæˆï¼è€—æ—¶: {training_time:.2f}ç§’")
        logger.info(f"è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
        # 4. è¯„ä¼°æ¨¡å‹
        if not args.train_only:
            print("\nğŸ“Š æ­¥éª¤ 4/5: è¯„ä¼°æ¨¡å‹")
            print("-" * 30)
            
            evaluator = ModelEvaluator(config)
            
            # åŠ è½½æœ€ä½³æ¨¡å‹
            best_model_path = os.path.join(config.experiment.checkpoint_dir, 'best_model.pth')
            
            if os.path.exists(best_model_path):
                model = evaluator.load_model(best_model_path, model)
            
            # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
            evaluation_start = time.time()
            report_path = evaluator.generate_evaluation_report(model, data_loader)
            evaluation_time = time.time() - evaluation_start
            
            print(f"âœ… è¯„ä¼°å®Œæˆï¼è€—æ—¶: {evaluation_time:.2f}ç§’")
            print(f"ğŸ“‹ è¯„ä¼°æŠ¥å‘Š: {report_path}")
            logger.info(f"è¯„ä¼°å®Œæˆï¼ŒæŠ¥å‘Šè·¯å¾„: {report_path}")
        
        # 5. ä¿å­˜å®éªŒé…ç½®å’Œæ‘˜è¦
        print("\nğŸ’¾ æ­¥éª¤ 5/5: ä¿å­˜å®éªŒç»“æœ")
        print("-" * 30)
        
        # ä¿å­˜é…ç½®
        config_path = os.path.join(config.experiment.output_dir, 'experiment_config.json')
        save_json(config.to_dict(), config_path)
        
        # åˆ›å»ºå®éªŒæ‘˜è¦
        summary_path = create_experiment_summary(config.experiment.output_dir)
        
        print(f"âœ… å®éªŒé…ç½®å·²ä¿å­˜: {config_path}")
        print(f"ğŸ“ å®éªŒæ‘˜è¦å·²ç”Ÿæˆ: {summary_path}")
        
        # æœ€ç»ˆç»“æœ
        print("\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.experiment.output_dir}")
        print(f"ğŸ“‹ å®éªŒæ‘˜è¦: {summary_path}")
        
        if not args.train_only:
            print(f"ğŸ“Š è¯„ä¼°æŠ¥å‘Š: {report_path}")
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        if hasattr(trainer, 'training_history') and trainer.training_history['metrics']:
            final_metrics = trainer.training_history['metrics'][-1]
            topo_metrics = final_metrics.get('topology', {})
            
            print("\nğŸ“ˆ æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:")
            print(f"  F1åˆ†æ•°: {topo_metrics.get('f1_score', 0):.3f}")
            print(f"  ç²¾ç¡®ç‡: {topo_metrics.get('precision', 0):.3f}")
            print(f"  å¬å›ç‡: {topo_metrics.get('recall', 0):.3f}")
            
            composite_score = final_metrics.get('composite_score', 0)
            print(f"  ç»¼åˆå¾—åˆ†: {composite_score:.3f}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        logger.warning("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise
    
    finally:
        # æ¸…ç†èµ„æº
        if 'trainer' in locals():
            if hasattr(trainer, 'writer') and trainer.writer:
                trainer.writer.close()


if __name__ == "__main__":
    main()