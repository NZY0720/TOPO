#!/usr/bin/env python3
"""
Data loading and preprocessing for Power Grid Topology Reconstruction
Updated for actual data format
"""

import os
import pandas as pd
import numpy as np
import torch
from torch_geometric.data import Data
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from typing import Tuple, List, Dict, Optional, Union
import warnings
warnings.filterwarnings('ignore')

from ..config.base_config import DataConfig
from ..utils.graph_utils import create_candidate_graph, ensure_connected_graph
from ..utils.io_utils import load_csv_safe


class PowerGridDataLoader:
    """ç”µåŠ›ç½‘æ ¼æ•°æ®åŠ è½½å™¨ - é€‚é…å®é™…æ•°æ®æ ¼å¼"""
    
    def __init__(self, config: DataConfig):
        self.config = config
        self.buses = None
        self.lines = None
        self.voltage_ts = None
        self.loading_ts = None
        self.loads = None
        self.generators = None
        self.final_state = None
        self.scaler = None
        
        # ç¼“å­˜çš„ç‰¹å¾
        self._node_features_cache = {}
        self._candidate_graph_cache = None
        self._true_topology_cache = None
        
        # å®é™…æ•°æ®æ–‡ä»¶åæ˜ å°„
        self.file_mapping = {
            'buses': '1MVurban0sw_bus_with_local_coords.csv',
            'lines': '1MVurban0sw_lines_with_coordinates.csv', 
            'voltage_ts': '1MVurban0sw_voltage_timeseries.csv',
            'loading_ts': '1MVurban0sw_loading_timeseries.csv',
            'loads': '1MVurban0sw_loads_with_coordinates.csv',
            'generators': '1MVurban0sw_generators_with_coordinates.csv',
            'final_state': '1MVurban0sw_final_state_with_coords.csv',
            'summary_stats': '1MVurban0sw_summary_statistics.csv',
            'original_coords': '1MVurban0sw_original_coordinates.csv'
        }
        
    def load_data(self, data_path: Optional[str] = None) -> None:
        """åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        if data_path is None:
            data_path = self.config.data_path
            
        self.data_path = data_path
        
        try:
            # 1. åŠ è½½èŠ‚ç‚¹æ•°æ® (buses)
            buses_file = os.path.join(data_path, self.file_mapping['buses'])
            self.buses = load_csv_safe(buses_file)
            print(f"âœ… èŠ‚ç‚¹æ•°æ®åŠ è½½å®Œæˆ: {len(self.buses)} ä¸ªèŠ‚ç‚¹")
            
            # 2. åŠ è½½çº¿è·¯æ•°æ® (lines)
            lines_file = os.path.join(data_path, self.file_mapping['lines'])
            self.lines = load_csv_safe(lines_file)
            print(f"âœ… çº¿è·¯æ•°æ®åŠ è½½å®Œæˆ: {len(self.lines)} æ¡çº¿è·¯")
            
            # 3. åŠ è½½ç”µå‹æ—¶é—´åºåˆ—
            voltage_file = os.path.join(data_path, self.file_mapping['voltage_ts'])
            self.voltage_ts = load_csv_safe(voltage_file)
            print(f"âœ… ç”µå‹æ—¶é—´åºåˆ—åŠ è½½å®Œæˆ: {len(self.voltage_ts)} ä¸ªæ—¶é—´æ­¥")
            
            # 4. åŠ è½½è´Ÿè½½æ—¶é—´åºåˆ—
            loading_file = os.path.join(data_path, self.file_mapping['loading_ts'])
            self.loading_ts = load_csv_safe(loading_file)
            print(f"âœ… è´Ÿè½½æ—¶é—´åºåˆ—åŠ è½½å®Œæˆ: {len(self.loading_ts)} ä¸ªæ—¶é—´æ­¥")
            
            # 5. åŠ è½½è´Ÿè½½æ•°æ® (å¯é€‰)
            loads_file = os.path.join(data_path, self.file_mapping['loads'])
            if os.path.exists(loads_file):
                self.loads = load_csv_safe(loads_file)
                print(f"âœ… è´Ÿè½½æ•°æ®åŠ è½½å®Œæˆ: {len(self.loads)} ä¸ªè´Ÿè½½ç‚¹")
            
            # 6. åŠ è½½å‘ç”µæœºæ•°æ® (å¯é€‰)
            gen_file = os.path.join(data_path, self.file_mapping['generators'])
            if os.path.exists(gen_file):
                self.generators = load_csv_safe(gen_file)
                print(f"âœ… å‘ç”µæœºæ•°æ®åŠ è½½å®Œæˆ: {len(self.generators)} ä¸ªå‘ç”µæœº")
            
            # 7. åŠ è½½æœ€ç»ˆçŠ¶æ€æ•°æ® (å¯é€‰)
            final_file = os.path.join(data_path, self.file_mapping['final_state'])
            if os.path.exists(final_file):
                self.final_state = load_csv_safe(final_file)
                print(f"âœ… æœ€ç»ˆçŠ¶æ€æ•°æ®åŠ è½½å®Œæˆ: {len(self.final_state)} ä¸ªçŠ¶æ€")
            
            # æ•°æ®éªŒè¯å’Œæ¸…ç†
            self._validate_and_clean_data()
            
            print(f"\nğŸ“Š æ•°æ®åŠ è½½æ€»ç»“:")
            print(f"   - èŠ‚ç‚¹æ•°: {len(self.buses)}")
            print(f"   - çº¿è·¯æ•°: {len(self.lines)}")
            print(f"   - æ—¶é—´æ­¥æ•°: {len(self.voltage_ts)}")
            print(f"   - è´Ÿè½½ç‚¹æ•°: {len(self.loads) if self.loads is not None else 0}")
            print(f"   - å‘ç”µæœºæ•°: {len(self.generators) if self.generators is not None else 0}")
            
        except Exception as e:
            raise RuntimeError(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    def _validate_and_clean_data(self) -> None:
        """éªŒè¯å’Œæ¸…ç†æ•°æ®"""
        print("ğŸ”§ æ•°æ®éªŒè¯å’Œæ¸…ç†...")
        
        # 1. éªŒè¯èŠ‚ç‚¹æ•°æ®
        if self.buses is not None:
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_bus_cols = ['x', 'y', 'vn_kv', 'type']
            missing_cols = [col for col in required_bus_cols if col not in self.buses.columns]
            if missing_cols:
                print(f"âš ï¸  èŠ‚ç‚¹æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}")
            
            # æ•°æ®æ¸…ç†
            self.buses['x'] = pd.to_numeric(self.buses['x'], errors='coerce').fillna(0.0)
            self.buses['y'] = pd.to_numeric(self.buses['y'], errors='coerce').fillna(0.0)
            self.buses['vn_kv'] = pd.to_numeric(self.buses['vn_kv'], errors='coerce').fillna(1.0)
            self.buses['voltLvl'] = self.buses.get('voltLvl', 1).fillna(1)
            self.buses['type'] = self.buses.get('type', 'b').fillna('b')
            
            # é‡ç½®ç´¢å¼•ç¡®ä¿è¿ç»­æ€§
            self.buses = self.buses.reset_index(drop=True)
            print(f"   âœ… èŠ‚ç‚¹æ•°æ®éªŒè¯å®Œæˆ: {len(self.buses)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹")
        
        # 2. éªŒè¯çº¿è·¯æ•°æ®
        if self.lines is not None:
            required_line_cols = ['from_bus', 'to_bus', 'in_service']
            missing_cols = [col for col in required_line_cols if col not in self.lines.columns]
            if missing_cols:
                print(f"âš ï¸  çº¿è·¯æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}")
            
            # æ•°æ®æ¸…ç†
            self.lines['from_bus'] = pd.to_numeric(self.lines['from_bus'], errors='coerce')
            self.lines['to_bus'] = pd.to_numeric(self.lines['to_bus'], errors='coerce')
            self.lines['in_service'] = self.lines.get('in_service', True).fillna(True)
            
            # çº¿è·¯å‚æ•°å¤„ç†
            self.lines['r_ohm_per_km'] = pd.to_numeric(
                self.lines.get('r_ohm_per_km', 0.1), errors='coerce'
            ).fillna(0.1)
            self.lines['x_ohm_per_km'] = pd.to_numeric(
                self.lines.get('x_ohm_per_km', 0.1), errors='coerce'
            ).fillna(0.1)
            self.lines['length_km'] = pd.to_numeric(
                self.lines.get('length_km', 0.1), errors='coerce'
            ).fillna(0.1)
            
            # ç§»é™¤æ— æ•ˆçº¿è·¯
            invalid_lines = (
                self.lines['from_bus'].isna() | 
                self.lines['to_bus'].isna() |
                (self.lines['from_bus'] >= len(self.buses)) |
                (self.lines['to_bus'] >= len(self.buses))
            )
            
            if invalid_lines.any():
                print(f"âš ï¸  ç§»é™¤ {invalid_lines.sum()} æ¡æ— æ•ˆçº¿è·¯")
                self.lines = self.lines[~invalid_lines].reset_index(drop=True)
            
            print(f"   âœ… çº¿è·¯æ•°æ®éªŒè¯å®Œæˆ: {len(self.lines)} æ¡æœ‰æ•ˆçº¿è·¯")
        
        # 3. éªŒè¯æ—¶é—´åºåˆ—æ•°æ®
        if self.voltage_ts is not None:
            # æ£€æŸ¥èŠ‚ç‚¹ç”µå‹åˆ—æ˜¯å¦å­˜åœ¨
            expected_bus_cols = [f'bus_{i}' for i in range(len(self.buses))]
            available_bus_cols = [col for col in expected_bus_cols if col in self.voltage_ts.columns]
            
            if len(available_bus_cols) < len(self.buses):
                print(f"âš ï¸  ç”µå‹æ—¶é—´åºåˆ—ç¼ºå°‘éƒ¨åˆ†èŠ‚ç‚¹æ•°æ®")
                print(f"     æœŸæœ›: {len(self.buses)} ä¸ªèŠ‚ç‚¹ï¼Œå®é™…: {len(available_bus_cols)} ä¸ªèŠ‚ç‚¹")
            
            print(f"   âœ… ç”µå‹æ—¶é—´åºåˆ—éªŒè¯å®Œæˆ: {len(self.voltage_ts)} ä¸ªæ—¶é—´æ­¥")
        
        # 4. éªŒè¯è´Ÿè½½æ•°æ®
        if self.loads is not None:
            # ç¡®ä¿è´Ÿè½½çš„busç´¢å¼•æœ‰æ•ˆ
            valid_load_buses = self.loads['bus'] < len(self.buses)
            if not valid_load_buses.all():
                print(f"âš ï¸  ç§»é™¤ {(~valid_load_buses).sum()} ä¸ªæ— æ•ˆè´Ÿè½½")
                self.loads = self.loads[valid_load_buses].reset_index(drop=True)
            
            print(f"   âœ… è´Ÿè½½æ•°æ®éªŒè¯å®Œæˆ: {len(self.loads)} ä¸ªè´Ÿè½½ç‚¹")
        
        # 5. éªŒè¯å‘ç”µæœºæ•°æ®
        if self.generators is not None:
            # ç¡®ä¿å‘ç”µæœºçš„busç´¢å¼•æœ‰æ•ˆ
            valid_gen_buses = self.generators['bus'] < len(self.buses)
            if not valid_gen_buses.all():
                print(f"âš ï¸  ç§»é™¤ {(~valid_gen_buses).sum()} ä¸ªæ— æ•ˆå‘ç”µæœº")
                self.generators = self.generators[valid_gen_buses].reset_index(drop=True)
            
            print(f"   âœ… å‘ç”µæœºæ•°æ®éªŒè¯å®Œæˆ: {len(self.generators)} ä¸ªå‘ç”µæœº")
    
    def mask_unobservable_nodes(self, ratio: Optional[float] = None, 
                               seed: Optional[int] = None) -> np.ndarray:
        """éšæœºé®è”½éƒ¨åˆ†èŠ‚ç‚¹ä½œä¸ºä¸å¯è§‚æµ‹"""
        if ratio is None:
            ratio = self.config.unobservable_ratio
            
        if seed is not None:
            np.random.seed(seed)
            
        n_nodes = len(self.buses)
        n_masked = int(n_nodes * ratio)
        
        # éšæœºé€‰æ‹©è¦é®è”½çš„èŠ‚ç‚¹
        masked_indices = np.random.choice(n_nodes, n_masked, replace=False)
        
        # è®¾ç½®å¯è§‚æµ‹æ€§æ ‡å¿—
        self.buses['observed'] = True
        self.buses.loc[masked_indices, 'observed'] = False
        
        print(f"ğŸ­ é®è”½äº† {n_masked}/{n_nodes} ä¸ªèŠ‚ç‚¹ ({ratio*100:.1f}%)")
        
        # æ¸…é™¤ç¼“å­˜
        self._node_features_cache.clear()
        
        return masked_indices
    
    def build_node_features(self, time_step: int = 0, use_cache: bool = True) -> torch.Tensor:
        """æ„å»ºèŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ"""
        cache_key = f"features_{time_step}"
        
        if use_cache and cache_key in self._node_features_cache:
            return self._node_features_cache[cache_key]
        
        features = []
        n_nodes = len(self.buses)
        
        for idx in range(n_nodes):
            bus = self.buses.iloc[idx]
            node_features = self._extract_node_features(bus, idx, time_step)
            features.append(node_features)
        
        # è½¬æ¢ä¸ºå¼ é‡
        feature_tensor = torch.tensor(features, dtype=torch.float32)
        
        # ç‰¹å¾å½’ä¸€åŒ–
        if self.config.normalize_features:
            if self.scaler is None:
                self.scaler = StandardScaler()
                feature_tensor = torch.tensor(
                    self.scaler.fit_transform(feature_tensor.numpy()),
                    dtype=torch.float32
                )
            else:
                feature_tensor = torch.tensor(
                    self.scaler.transform(feature_tensor.numpy()),
                    dtype=torch.float32
                )
        
        # æ·»åŠ å™ªå£°ï¼ˆæ•°æ®å¢å¼ºï¼‰
        if self.config.add_noise and self.config.noise_std > 0:
            noise = torch.randn_like(feature_tensor) * self.config.noise_std
            feature_tensor += noise
        
        # ç¼“å­˜ç‰¹å¾
        if use_cache:
            self._node_features_cache[cache_key] = feature_tensor
            
        return feature_tensor
    
    def _extract_node_features(self, bus: pd.Series, bus_idx: int, time_step: int) -> List[float]:
        """æå–å•ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾"""
        features = []
        
        # 1. ç”µæ°”æµ‹é‡ç‰¹å¾
        if bus.get('observed', True):
            # ç”µå‹ç‰¹å¾ï¼ˆä»æ—¶é—´åºåˆ—è·å–ï¼‰
            voltage = self._get_voltage_measurement(bus_idx, time_step)
            
            # å°†ç”µå‹è½¬æ¢ä¸ºå®éƒ¨è™šéƒ¨ï¼ˆå‡è®¾ç›¸è§’ä¸º0ï¼Œç®€åŒ–å¤„ç†ï¼‰
            v_real = voltage * np.cos(0)  
            v_imag = voltage * np.sin(0)
            
            # åŠŸç‡ç‰¹å¾ï¼ˆä»è´Ÿè½½æ•°æ®è·å–æˆ–æ¨¡æ‹Ÿï¼‰
            p_load, q_load = self._get_power_measurements(bus_idx, time_step)
            
            # å‘ç”µæœºåŠŸç‡ï¼ˆå¦‚æœè¯¥èŠ‚ç‚¹æœ‰å‘ç”µæœºï¼‰
            p_gen, q_gen = self._get_generator_measurements(bus_idx)
            
        else:
            # ä¸å¯è§‚æµ‹èŠ‚ç‚¹ç‰¹å¾ç½®é›¶
            v_real = v_imag = p_load = q_load = p_gen = q_gen = 0.0
        
        features.extend([v_real, v_imag, p_load, q_load, p_gen, q_gen])
        
        # 2. ç©ºé—´ç‰¹å¾
        x_coord = float(bus['x'])
        y_coord = float(bus['y'])
        
        # ç©ºé—´æŠ–åŠ¨ï¼ˆæ•°æ®å¢å¼ºï¼‰
        if self.config.spatial_jitter > 0:
            x_coord += np.random.normal(0, self.config.spatial_jitter)
            y_coord += np.random.normal(0, self.config.spatial_jitter)
            
        features.extend([x_coord, y_coord])
        
        # 3. ç»“æ„ç‰¹å¾
        volt_level = float(bus.get('vn_kv', 1.0))  # ä½¿ç”¨å®é™…ç”µå‹ç­‰çº§
        bus_type_encoding = self._encode_bus_type(bus.get('type', 'b'))
        is_observed = float(bus.get('observed', True))
        
        # æ·»åŠ å­ç½‘ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        subnet_encoding = self._encode_subnet(bus.get('subnet', 'default'))
        
        features.extend([volt_level, bus_type_encoding, is_observed, subnet_encoding])
        
        # 4. ç½‘ç»œæ‹“æ‰‘ç‰¹å¾
        degree = self._get_node_degree(bus_idx)
        features.append(degree)
        
        return features
    
    def _get_voltage_measurement(self, bus_idx: int, time_step: int) -> float:
        """è·å–ç”µå‹æµ‹é‡å€¼"""
        voltage_col = f'bus_{bus_idx}'
        
        if (self.voltage_ts is not None and 
            voltage_col in self.voltage_ts.columns and 
            time_step < len(self.voltage_ts)):
            voltage = self.voltage_ts.iloc[time_step][voltage_col]
            return float(voltage) if pd.notna(voltage) else 1.0
        else:
            # é»˜è®¤æ ‡å¹ºå€¼
            return 1.0 + np.random.normal(0, 0.02)
    
    def _get_power_measurements(self, bus_idx: int, time_step: int) -> Tuple[float, float]:
        """è·å–åŠŸç‡æµ‹é‡å€¼"""
        p_load = q_load = 0.0
        
        if self.loads is not None:
            # æŸ¥æ‰¾è¯¥èŠ‚ç‚¹çš„è´Ÿè½½
            bus_loads = self.loads[self.loads['bus'] == bus_idx]
            if not bus_loads.empty:
                for _, load in bus_loads.iterrows():
                    p_load += float(load.get('p_mw', 0))
                    q_load += float(load.get('q_mvar', 0))
        
        # å¦‚æœæ²¡æœ‰è´Ÿè½½æ•°æ®ï¼Œä½¿ç”¨å°çš„éšæœºå€¼
        if p_load == 0 and q_load == 0:
            p_load = max(0, np.random.normal(0.02, 0.01))
            q_load = max(0, np.random.normal(0.01, 0.005))
        
        return p_load, q_load
    
    def _get_generator_measurements(self, bus_idx: int) -> Tuple[float, float]:
        """è·å–å‘ç”µæœºåŠŸç‡æµ‹é‡å€¼"""
        p_gen = q_gen = 0.0
        
        if self.generators is not None:
            # æŸ¥æ‰¾è¯¥èŠ‚ç‚¹çš„å‘ç”µæœº
            bus_gens = self.generators[self.generators['bus'] == bus_idx]
            if not bus_gens.empty:
                for _, gen in bus_gens.iterrows():
                    if gen.get('in_service', True):
                        p_gen += float(gen.get('p_mw', 0))
                        q_gen += float(gen.get('q_mvar', 0))
        
        return p_gen, q_gen
    
    def _encode_bus_type(self, bus_type: str) -> float:
        """ç¼–ç èŠ‚ç‚¹ç±»å‹"""
        type_mapping = {
            'b': 0,      # æ™®é€šèŠ‚ç‚¹
            'db': 1,     # åˆ†å¸ƒå¼èŠ‚ç‚¹  
            'auxiliary': 2,  # è¾…åŠ©èŠ‚ç‚¹
            'n': 0,      # èŠ‚ç‚¹
            'gen': 3,    # å‘ç”µæœºèŠ‚ç‚¹
            'load': 4    # è´Ÿè½½èŠ‚ç‚¹
        }
        return float(type_mapping.get(str(bus_type).lower(), 0))
    
    def _encode_subnet(self, subnet: str) -> float:
        """ç¼–ç å­ç½‘ä¿¡æ¯"""
        if pd.isna(subnet) or subnet == 'default':
            return 0.0
        
        # ç®€å•çš„å“ˆå¸Œç¼–ç 
        return float(hash(str(subnet)) % 10)
    
    def _get_node_degree(self, bus_idx: int) -> float:
        """è·å–èŠ‚ç‚¹åº¦æ•°ï¼ˆåœ¨çœŸå®æ‹“æ‰‘ä¸­ï¼‰"""
        if self.lines is None:
            return 0.0
            
        degree = 0
        for _, line in self.lines.iterrows():
            if (line.get('in_service', True) and 
                (line.get('from_bus') == bus_idx or line.get('to_bus') == bus_idx)):
                degree += 1
                
        return float(degree)
    
    def build_candidate_graph(self, k: Optional[int] = None, 
                            method: str = 'knn') -> Tuple[torch.Tensor, torch.Tensor]:
        """æ„å»ºå€™é€‰å›¾"""
        if k is None:
            k = self.config.candidate_k_neighbors
            
        if self._candidate_graph_cache is None:
            coords = self.buses[['x', 'y']].values
            edge_index, edge_distances = create_candidate_graph(
                coords, k=k, method=method
            )
            
            # ç¡®ä¿å›¾è¿é€šæ€§
            if edge_index.shape[1] > 0:
                edge_index = ensure_connected_graph(edge_index, len(self.buses))
            
            self._candidate_graph_cache = (
                torch.tensor(edge_index, dtype=torch.long),
                torch.tensor(edge_distances, dtype=torch.float32).unsqueeze(1)
            )
        
        return self._candidate_graph_cache
    
    def get_true_topology(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """è·å–çœŸå®æ‹“æ‰‘ç»“æ„"""
        if self._true_topology_cache is not None:
            return self._true_topology_cache
            
        true_edges = []
        true_params = []
        
        if self.lines is not None:
            for _, line in self.lines.iterrows():
                # æ£€æŸ¥çº¿è·¯æ˜¯å¦æŠ•è¿ä¸”æœ‰æ•ˆ
                if (line.get('in_service', True) and 
                    pd.notna(line.get('from_bus')) and 
                    pd.notna(line.get('to_bus'))):
                    
                    from_bus = int(line['from_bus'])
                    to_bus = int(line['to_bus'])
                    
                    # ç¡®ä¿èŠ‚ç‚¹ç´¢å¼•æœ‰æ•ˆ
                    if (from_bus < len(self.buses) and to_bus < len(self.buses) and
                        from_bus >= 0 and to_bus >= 0 and from_bus != to_bus):
                        
                        true_edges.append([from_bus, to_bus])
                        
                        # è®¡ç®—çº¿è·¯å‚æ•°
                        r_per_km = float(line.get('r_ohm_per_km', 0.1))
                        x_per_km = float(line.get('x_ohm_per_km', 0.1))
                        length = float(line.get('length_km', 0.1))
                        
                        r_total = r_per_km * length
                        x_total = x_per_km * length
                        
                        # ç¡®ä¿å‚æ•°ä¸ºæ­£æ•°
                        r_total = max(r_total, 1e-6)
                        x_total = max(x_total, 1e-6)
                        
                        true_params.append([r_total, x_total])
        
        if true_edges:
            true_edge_index = torch.tensor(true_edges, dtype=torch.long).t().contiguous()
            true_edge_params = torch.tensor(true_params, dtype=torch.float32)
        else:
            true_edge_index = torch.empty((2, 0), dtype=torch.long)
            true_edge_params = torch.empty((0, 2), dtype=torch.float32)
        
        self._true_topology_cache = (true_edge_index, true_edge_params)
        return self._true_topology_cache
    
    def create_graph_data(self, time_step: int = 0) -> Data:
        """åˆ›å»ºPyTorch Geometricå›¾æ•°æ®å¯¹è±¡"""
        # èŠ‚ç‚¹ç‰¹å¾
        x = self.build_node_features(time_step)
        
        # å€™é€‰è¾¹
        edge_index, edge_attr = self.build_candidate_graph()
        
        # çœŸå®æ‹“æ‰‘ï¼ˆç”¨äºè®­ç»ƒï¼‰
        true_edge_index, true_edge_params = self.get_true_topology()
        
        # åˆ›å»ºæ•°æ®å¯¹è±¡
        data = Data(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_attr,
            true_edge_index=true_edge_index,
            true_edge_params=true_edge_params,
            num_nodes=len(self.buses)
        )
        
        return data
    
    def get_data_info(self) -> Dict[str, Union[int, float]]:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        if self.buses is None:
            return {}
            
        info = {
            'num_nodes': len(self.buses),
            'num_lines': len(self.lines) if self.lines is not None else 0,
            'num_time_steps': len(self.voltage_ts) if self.voltage_ts is not None else 0,
            'num_loads': len(self.loads) if self.loads is not None else 0,
            'num_generators': len(self.generators) if self.generators is not None else 0,
            'observable_ratio': self.buses.get('observed', True).mean() if 'observed' in self.buses.columns else 1.0,
            'feature_dim': len(self._extract_node_features(self.buses.iloc[0], 0, 0)),
            'spatial_extent_x': self.buses['x'].max() - self.buses['x'].min(),
            'spatial_extent_y': self.buses['y'].max() - self.buses['y'].min(),
        }
        
        # ç”µå‹ç­‰çº§åˆ†å¸ƒ
        if 'vn_kv' in self.buses.columns:
            info['voltage_levels'] = sorted(self.buses['vn_kv'].unique().tolist())
        
        # çº¿è·¯é•¿åº¦ç»Ÿè®¡
        if self.lines is not None and 'length_km' in self.lines.columns:
            info['avg_line_length'] = float(self.lines['length_km'].mean())
            info['max_line_length'] = float(self.lines['length_km'].max())
            info['min_line_length'] = float(self.lines['length_km'].min())
        
        return info
    
    def get_network_statistics(self) -> Dict[str, Any]:
        """è·å–ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        if self.buses is not None:
            stats['nodes'] = {
                'total': len(self.buses),
                'voltage_levels': self.buses['vn_kv'].value_counts().to_dict() if 'vn_kv' in self.buses.columns else {},
                'node_types': self.buses['type'].value_counts().to_dict() if 'type' in self.buses.columns else {}
            }
        
        if self.lines is not None:
            stats['lines'] = {
                'total': len(self.lines),
                'in_service': self.lines['in_service'].sum() if 'in_service' in self.lines.columns else len(self.lines),
                'avg_length': float(self.lines['length_km'].mean()) if 'length_km' in self.lines.columns else 0,
                'total_length': float(self.lines['length_km'].sum()) if 'length_km' in self.lines.columns else 0
            }
        
        if self.loads is not None:
            stats['loads'] = {
                'total': len(self.loads),
                'total_p': float(self.loads['p_mw'].sum()) if 'p_mw' in self.loads.columns else 0,
                'total_q': float(self.loads['q_mvar'].sum()) if 'q_mvar' in self.loads.columns else 0
            }
        
        if self.generators is not None:
            stats['generators'] = {
                'total': len(self.generators),
                'in_service': self.generators['in_service'].sum() if 'in_service' in self.generators.columns else len(self.generators),
                'total_p': float(self.generators['p_mw'].sum()) if 'p_mw' in self.generators.columns else 0,
                'total_q': float(self.generators['q_mvar'].sum()) if 'q_mvar' in self.generators.columns else 0
            }
        
        return stats
    
    def clear_cache(self) -> None:
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        self._node_features_cache.clear()
        self._candidate_graph_cache = None
        self._true_topology_cache = None
    
    def save_processed_data(self, output_path: str) -> None:
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        processed_data = {
            'buses': self.buses,
            'lines': self.lines,
            'loads': self.loads,
            'generators': self.generators,
            'config': self.config.__dict__
        }
        
        import pickle
        with open(output_path, 'wb') as f:
            pickle.dump(processed_data, f)
        
        print(f"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")